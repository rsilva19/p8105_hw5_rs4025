---
title: "Hw 5 p8105"
author: "Rebecca Silva"
date: "11/07/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(p8105.datasets)
library(kableExtra)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	message = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


### Problem 1 

```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

input = iris_with_missing$Sepal.Length

fill_missing = function(vec){
  if(is.numeric(vec)){
    ifelse(is.na(vec), mean(vec, na.rm = T), vec)
  }else{
    ifelse(is.na(vec), "virginica", vec)
  }
}

iris_filled = map(iris_with_missing, fill_missing)
is.na(iris_filled)
```


### Problem 2 

```{r}
df = tibble(
  names = list.files("data 4")
)
tidy_df = 
  df %>% 
  mutate(patient = map(str_c("./data 4/",names), read.csv)) %>% 
  unnest(cols = c(patient)) %>% 
  mutate(n = c(1:nrow(.))) %>% 
  separate(names, 
           into = c("arm", "id"), 
           sep = "_") %>% 
  pivot_longer(
    week_1:week_8, 
    names_to = "week", 
    values_to = "value"
  ) %>% 
  mutate(week = as.numeric(str_remove(week, "week_")), 
         id = as.numeric(str_remove(id, ".csv")))
```

```{r}
# spaghetti plot 
tidy_df %>% 
  mutate(id_arm = str_c(arm, id, sep = "_")) %>% 
  ggplot(aes( x = week, y = value, color = id_arm)) + 
  geom_line(aes(group = id_arm, linetype = arm)) + 
  labs(
    title = "Observation for each subject over 8 weeks",
    x = "Week",
    y = "Observation") +
  theme(plot.title = element_text(hjust = 0.5), 
        legend.position = "bottom") +
  guides(color = FALSE) +
  scale_linetype_discrete(name = "Arm", labels = c("control", "experimental"))
```

The spaghetti plot shows that over the course of 8 weeks individual's observations in the experimental group increase while individual's observations in the control group tend to stay fluctuating around lower observations and may even decrease.  

### Problem 3

```{r}
# function
generate_data = function( beta1, n = 30, beta0 = 2, var_error = 50 ){

  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, sd = sqrt(var_error))
  )
  
  result  = # extract p-val and est
    lm(y ~ x, data = sim_data) %>% 
    summary() %>% 
    broom::tidy() %>%  
    filter(term == "x") %>% 
    select(estimate, p.value)
}
```

```{r}
# beta1 = 0
data = generate_data(beta1 = 0)
bind_rows(data)
```


```{r}
# beta = 1-6

set.seed(1)
sim_results = 
  tibble(beta1 = c(1:6)) %>% 
  mutate(
    output_lists = map(.x = beta1, ~rerun(1000, generate_data(beta1 = .x))),
    estPval = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estPval)
```

```{r}
sim_results %>% 
  mutate( reject = ifelse(p.value < 0.05, TRUE, FALSE)) %>% 
  group_by(beta1) %>% 
  summarise(prop = sum(reject)/n()) %>% 
  ggplot(aes( x = beta1, y = prop, fill = beta1)) + geom_bar(stat = "identity")
```

In the case of simple linear regression, effect size is equivalent to $\beta_1$. As effect size increases, the probability of rejecting the null increases, ie the power increases. This makes sense since the null hypothesis is that $\beta_1$ = 0, so as the true $\beta_1$ gets farther from 0, it is more likely that our simulated data will find $\hat{\beta_1}$ is significantly different from 0, using an alpha level of 0.05. 

```{r}
data1= sim_results %>% 
  group_by(beta1) %>% 
  summarize(mean = mean(estimate)) %>% 
   cbind(data = rep("data1",nrow(.)))

data2 = sim_results %>% 
  mutate( reject = ifelse(p.value < 0.05, TRUE, FALSE)) %>% 
  group_by(beta1, reject) %>% 
  summarize(mean = mean(estimate)) %>% 
  filter(reject) %>% 
  cbind(data = rep("data2",nrow(.))) %>% 
  select(-reject)

data = bind_rows(data1, data2)

# plot 
ggplot(data, aes( x = beta1, y = mean, color = data)) +
  geom_line() +
  labs(
    title = "Mean estimate of Beta1 Vs. True Beta1",
    x = "Beta 1",
    y = "Mean Estimate") +
  scale_color_discrete(name = "", 
                       labels = c("all betas", "null rejected")) +
  theme(plot.title = element_text(hjust = 0.5))

```

The sample average of $\hat{\beta_1}$ across tests for which the null is rejected is greater than the true value of $\beta_1$ for all betas not equal to 0. More specifically, the sample average gets closer to the true beta as beta increases. This is because we are more likely to reject a test when the estimated $\beta_1$ is not equal to the true $\beta_1$ value. Since we are more likely to reject a test as the true $\beta_1$ grows (from the above plot), the average sample of $\beta$ grows closer to the true $\beta_1$ as the true beta increases.
